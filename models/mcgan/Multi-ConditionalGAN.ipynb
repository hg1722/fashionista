{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt # plotting\nimport matplotlib.image as mpimg\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os # accessing directory structure\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, LeakyReLU, BatchNormalization\nfrom keras.layers import Conv2D, Conv2DTranspose, Reshape, Flatten\nfrom keras.layers import Input, Flatten, Embedding, multiply, Dropout\nfrom keras.layers import Concatenate, GaussianNoise,Activation\nfrom keras.optimizers import Adam\nfrom keras.utils import np_utils, to_categorical\nfrom keras import initializers\nfrom keras import backend as K","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/fashion-product-images-small/myntradataset/\"\nprint(os.listdir(DATASET_PATH))","execution_count":2,"outputs":[{"output_type":"stream","text":"['styles.csv', 'images']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(DATASET_PATH + \"styles.csv\", nrows=5000, error_bad_lines=False)\ndf['image'] = df.apply(lambda row: str(row['id']) + \".jpg\", axis=1)\ndf = df.reset_index(drop=True)\ndf.head(10)","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"      id gender masterCategory subCategory  articleType baseColour  season  \\\n0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n5   1855    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n6  30805    Men        Apparel     Topwear       Shirts      Green  Summer   \n7  26960  Women        Apparel     Topwear       Shirts     Purple  Summer   \n8  29114    Men    Accessories       Socks        Socks  Navy Blue  Summer   \n9  30039    Men    Accessories     Watches      Watches      Black  Winter   \n\n   year   usage                             productDisplayName      image  \n0  2011  Casual               Turtle Check Men Navy Blue Shirt  15970.jpg  \n1  2012  Casual             Peter England Men Party Blue Jeans  39386.jpg  \n2  2016  Casual                       Titan Women Silver Watch  59263.jpg  \n3  2011  Casual  Manchester United Men Solid Black Track Pants  21379.jpg  \n4  2012  Casual                          Puma Men Grey T-shirt  53759.jpg  \n5  2011  Casual           Inkfruit Mens Chain Reaction T-shirt   1855.jpg  \n6  2012  Ethnic               Fabindia Men Striped Green Shirt  30805.jpg  \n7  2012  Casual                  Jealous 21 Women Purple Shirt  26960.jpg  \n8  2012  Casual                       Puma Men Pack of 3 Socks  29114.jpg  \n9  2016  Casual                         Skagen Men Black Watch  30039.jpg  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>gender</th>\n      <th>masterCategory</th>\n      <th>subCategory</th>\n      <th>articleType</th>\n      <th>baseColour</th>\n      <th>season</th>\n      <th>year</th>\n      <th>usage</th>\n      <th>productDisplayName</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15970</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Shirts</td>\n      <td>Navy Blue</td>\n      <td>Fall</td>\n      <td>2011</td>\n      <td>Casual</td>\n      <td>Turtle Check Men Navy Blue Shirt</td>\n      <td>15970.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>39386</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Bottomwear</td>\n      <td>Jeans</td>\n      <td>Blue</td>\n      <td>Summer</td>\n      <td>2012</td>\n      <td>Casual</td>\n      <td>Peter England Men Party Blue Jeans</td>\n      <td>39386.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>59263</td>\n      <td>Women</td>\n      <td>Accessories</td>\n      <td>Watches</td>\n      <td>Watches</td>\n      <td>Silver</td>\n      <td>Winter</td>\n      <td>2016</td>\n      <td>Casual</td>\n      <td>Titan Women Silver Watch</td>\n      <td>59263.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>21379</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Bottomwear</td>\n      <td>Track Pants</td>\n      <td>Black</td>\n      <td>Fall</td>\n      <td>2011</td>\n      <td>Casual</td>\n      <td>Manchester United Men Solid Black Track Pants</td>\n      <td>21379.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>53759</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Tshirts</td>\n      <td>Grey</td>\n      <td>Summer</td>\n      <td>2012</td>\n      <td>Casual</td>\n      <td>Puma Men Grey T-shirt</td>\n      <td>53759.jpg</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1855</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Tshirts</td>\n      <td>Grey</td>\n      <td>Summer</td>\n      <td>2011</td>\n      <td>Casual</td>\n      <td>Inkfruit Mens Chain Reaction T-shirt</td>\n      <td>1855.jpg</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>30805</td>\n      <td>Men</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Shirts</td>\n      <td>Green</td>\n      <td>Summer</td>\n      <td>2012</td>\n      <td>Ethnic</td>\n      <td>Fabindia Men Striped Green Shirt</td>\n      <td>30805.jpg</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>26960</td>\n      <td>Women</td>\n      <td>Apparel</td>\n      <td>Topwear</td>\n      <td>Shirts</td>\n      <td>Purple</td>\n      <td>Summer</td>\n      <td>2012</td>\n      <td>Casual</td>\n      <td>Jealous 21 Women Purple Shirt</td>\n      <td>26960.jpg</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>29114</td>\n      <td>Men</td>\n      <td>Accessories</td>\n      <td>Socks</td>\n      <td>Socks</td>\n      <td>Navy Blue</td>\n      <td>Summer</td>\n      <td>2012</td>\n      <td>Casual</td>\n      <td>Puma Men Pack of 3 Socks</td>\n      <td>29114.jpg</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>30039</td>\n      <td>Men</td>\n      <td>Accessories</td>\n      <td>Watches</td>\n      <td>Watches</td>\n      <td>Black</td>\n      <td>Winter</td>\n      <td>2016</td>\n      <td>Casual</td>\n      <td>Skagen Men Black Watch</td>\n      <td>30039.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = df\ntest['subCategory'].value_counts().head(10)","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"Topwear       1610\nShoes          849\nBags           381\nWatches        322\nBottomwear     306\nInnerwear      226\nJewellery      145\nFragrance      128\nSandal         113\nWallets        108\nName: subCategory, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generating apparel type/color combinations\n\n# df = df[df['masterCategory'] == 'Apparel']\n# top_classes = df['articleType'].value_counts().index[:6].to_list()\n# top_colors = df['baseColour'].value_counts().index[:6].to_list()\n# df = df[df['articleType'].isin(top_classes)]\n# df = df[df['baseColour'].isin(top_colors)]\n# df = df.reset_index(drop=True)\n# clothing_types = df['articleType'].to_list()\n# clothing_colors = df['baseColour'].to_list()\n# image_names = df['image'].to_list()\n\n# Generating specific fashion type/ color combinations\ntop_categories = ['Topwear', 'Bottomwear', 'Shoes']\ntop_colors = ['Black', 'White', \"Blue\"]\n\ndf = df[df['subCategory'].isin(top_categories)]\ndf = df[df['baseColour'].isin(top_colors)]\ndf = df.reset_index(drop=True)\nclothing_types = df['subCategory'].to_list()\nclothing_colors = df['baseColour'].to_list()\nimage_names = df['image'].to_list()","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nfrom sklearn.preprocessing import LabelEncoder\n\ndata = []\nfor i, image_name in enumerate(image_names):\n    img = cv2.imread(DATASET_PATH + 'images/' + image_name)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n    img = cv2.resize(img, (64, 64))\n    img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    data.append(img)\n        \nX_train = np.array(data)\n\ny_type = np.array(clothing_types)\ny_color = np.array(clothing_colors)\n\nlabel_encoder = LabelEncoder()\n\nlabel_encoder.fit(y_type)\ntype_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n\nlabel_encoder.fit(y_color)\ncolor_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n\ny_type = label_encoder.fit_transform(y_type)\ny_color = label_encoder.fit_transform(y_color)\n\nprint(type_mapping)\nprint(color_mapping)","execution_count":6,"outputs":[{"output_type":"stream","text":"{'Bottomwear': 0, 'Shoes': 1, 'Topwear': 2}\n{'Black': 0, 'Blue': 1, 'White': 2}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_type.shape, y_color.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"((1340, 64, 64, 3), (1340,), (1340,))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(np.amin(X_train), np.amax(X_train))\n\nplt.imshow(X_train[46], interpolation='nearest')\nplt.show()\nprint(y_type[46], y_color[46])","execution_count":8,"outputs":[{"output_type":"stream","text":"-4.8428774e-08 1.0000001\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":"1 0\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_TYPES = len(np.unique(y_type))\nNUM_COLORS = len(np.unique(y_color))\n\nNUM_TYPES, NUM_COLORS","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"(3, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# latent space dimension\nz = Input(shape=(100,))\n\n# classes\ntypes = Input(shape=(NUM_TYPES,))\ncolors = Input(shape=(NUM_COLORS,))\n\n# Generator network\nmerged_layer = Concatenate()([z, types, colors])\n\n# FC: 2x2x1024\ngenerator = Dense(2*2*1024, activation='relu')(merged_layer)\ngenerator = BatchNormalization(momentum=0.9)(generator)\ngenerator = LeakyReLU(alpha=0.1)(generator)\ngenerator = Reshape((2, 2, 1024))(generator)\n\n# # Conv 1: 4x4x512\ngenerator = Conv2DTranspose(512, kernel_size=5, strides=2, padding='same')(generator)\ngenerator = BatchNormalization(momentum=0.9)(generator)\ngenerator = LeakyReLU(alpha=0.1)(generator)\n\n# Conv 2: 8x8x256\ngenerator = Conv2DTranspose(256, kernel_size=5, strides=2, padding='same')(generator)\ngenerator = BatchNormalization(momentum=0.9)(generator)\ngenerator = LeakyReLU(alpha=0.1)(generator)\n\n# Conv 3: 16x16x128\ngenerator = Conv2DTranspose(128, kernel_size=5, strides=2, padding='same')(generator)\ngenerator = BatchNormalization(momentum=0.9)(generator)\ngenerator = LeakyReLU(alpha=0.1)(generator)\n\n# Conv 4: 32x32x64\ngenerator = Conv2DTranspose(64, kernel_size=5, strides=2, padding='same')(generator)\ngenerator = BatchNormalization(momentum=0.9)(generator)\ngenerator = LeakyReLU(alpha=0.1)(generator)\n\n# Conv 5: 64x64x3\ngenerator = Conv2DTranspose(3, kernel_size=5, strides=2, padding='same', activation='tanh')(generator)\ngenerator = Model(inputs=[z, types, colors], outputs=generator, name='generator')","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generator.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"generator\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 100)          0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, 3)            0                                            \n__________________________________________________________________________________________________\ninput_3 (InputLayer)            (None, 3)            0                                            \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 106)          0           input_1[0][0]                    \n                                                                 input_2[0][0]                    \n                                                                 input_3[0][0]                    \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 4096)         438272      concatenate_1[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_1 (BatchNor (None, 4096)         16384       dense_1[0][0]                    \n__________________________________________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)       (None, 4096)         0           batch_normalization_1[0][0]      \n__________________________________________________________________________________________________\nreshape_1 (Reshape)             (None, 2, 2, 1024)   0           leaky_re_lu_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_transpose_1 (Conv2DTrans (None, 4, 4, 512)    13107712    reshape_1[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_2 (BatchNor (None, 4, 4, 512)    2048        conv2d_transpose_1[0][0]         \n__________________________________________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)       (None, 4, 4, 512)    0           batch_normalization_2[0][0]      \n__________________________________________________________________________________________________\nconv2d_transpose_2 (Conv2DTrans (None, 8, 8, 256)    3277056     leaky_re_lu_2[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_3 (BatchNor (None, 8, 8, 256)    1024        conv2d_transpose_2[0][0]         \n__________________________________________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)       (None, 8, 8, 256)    0           batch_normalization_3[0][0]      \n__________________________________________________________________________________________________\nconv2d_transpose_3 (Conv2DTrans (None, 16, 16, 128)  819328      leaky_re_lu_3[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_4 (BatchNor (None, 16, 16, 128)  512         conv2d_transpose_3[0][0]         \n__________________________________________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 128)  0           batch_normalization_4[0][0]      \n__________________________________________________________________________________________________\nconv2d_transpose_4 (Conv2DTrans (None, 32, 32, 64)   204864      leaky_re_lu_4[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_transpose_4[0][0]         \n__________________________________________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n__________________________________________________________________________________________________\nconv2d_transpose_5 (Conv2DTrans (None, 64, 64, 3)    4803        leaky_re_lu_5[0][0]              \n==================================================================================================\nTotal params: 17,872,259\nTrainable params: 17,862,147\nNon-trainable params: 10,112\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# input image\nimg_input = Input(shape=(X_train[0].shape))\n\ndiscriminator = Conv2D(32, kernel_size=5, strides=2, padding='same')(img_input)\ndiscriminator = BatchNormalization(momentum=0.9)(discriminator)\ndiscriminator = LeakyReLU(alpha=0.1)(discriminator)\n\n# Conv 1: 16x16x64\ndiscriminator = Conv2D(64, kernel_size=5, strides=2, padding='same')(img_input)\ndiscriminator = BatchNormalization(momentum=0.9)(discriminator)\ndiscriminator = LeakyReLU(alpha=0.1)(discriminator)\n\n# Conv 2:\ndiscriminator = Conv2D(128, kernel_size=5, strides=2, padding='same')(discriminator)\ndiscriminator = BatchNormalization(momentum=0.9)(discriminator)\ndiscriminator = LeakyReLU(alpha=0.1)(discriminator)\n\n# Conv 3: \ndiscriminator = Conv2D(256, kernel_size=5, strides=2, padding='same')(discriminator)\ndiscriminator = BatchNormalization(momentum=0.9)(discriminator)\ndiscriminator = LeakyReLU(alpha=0.1)(discriminator)\n\n# Conv 4: \ndiscriminator = Conv2D(512, kernel_size=5, strides=2, padding='same')(discriminator)\ndiscriminator = BatchNormalization(momentum=0.9)(discriminator)\ndiscriminator = LeakyReLU(alpha=0.1)(discriminator)\n\n# FC\ndiscriminator = Flatten()(discriminator)\n\n# Concatenate \nmerged_layer = Concatenate()([discriminator, types, colors])\ndiscriminator = Dense(512, activation='relu')(merged_layer)\n    \n# Output\ndiscriminator = Dense(1, activation='sigmoid')(discriminator)\n\ndiscriminator = Model(inputs=[img_input, types, colors], outputs=discriminator, name='discriminator')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"discriminator.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Optimizer\ndiscriminator.compile(Adam(lr=0.0002, beta_1=0.5), loss='binary_crossentropy',\n                      metrics=['binary_accuracy'])\n\ndiscriminator.trainable = False\n\n# label = Input(shape=(NUM_CLASSES,), name='label')\nclothing_type = Input(shape=(NUM_TYPES,), name='type')\nclothing_color = Input(shape=(NUM_COLORS,), name='color')\nz = Input(shape=(100,), name='z')\n\nfake_img = generator([z, clothing_type, clothing_color])\nvalidity = discriminator([fake_img, clothing_type, clothing_color])\n\nd_g = Model([z, clothing_type, clothing_color], validity, name='adversarial')\n\nd_g.compile(Adam(lr=0.0004, beta_1=0.5), loss='binary_crossentropy',\n            metrics=['binary_accuracy'])\n\n# prints a summary representation of your model\nd_g.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 300\nbatch_size = 32\nsmooth = 0.1\nlatent_dim = 100\n\nreal = np.ones(shape=(batch_size, 1))\nfake = np.zeros(shape=(batch_size, 1))\n\nd_loss = []\nd_g_loss = []\n\nfor e in range(epochs + 1):\n    for i in range(len(X_train) // batch_size):\n        \n        # Train Discriminator weights\n        discriminator.trainable = True\n        \n        # Real samples\n        X_batch = X_train[i*batch_size:(i+1)*batch_size]\n        # real_labels = to_categorical(y_train[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_CLASSES)\n        real_types = to_categorical(y_type[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_TYPES)\n        real_colors = to_categorical(y_color[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_COLORS)\n        \n        d_loss_real = discriminator.train_on_batch(x=[X_batch, real_types, real_colors],\n                                                   y=real * (1 - smooth))\n        \n        # Fake Samples\n        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n        # random_labels = to_categorical(np.random.randint(0, NUM_CLASSES, batch_size).reshape(-1, 1), num_classes=NUM_CLASSES)\n        random_types = to_categorical(y_type[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_TYPES)\n        random_colors = to_categorical(y_color[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_COLORS)\n        X_fake = generator.predict_on_batch([z, random_types, random_colors])\n        \n        d_loss_fake = discriminator.train_on_batch(x=[X_fake, random_types, random_colors], y=fake)\n  \n        # Discriminator loss\n        d_loss_batch = 0.5 * (d_loss_real[0] + d_loss_fake[0])\n        \n        # Train Generator weights\n        discriminator.trainable = False\n        \n        z = np.random.normal(loc=0, scale=1, size=(batch_size, latent_dim))\n        # random_labels = to_categorical(np.random.randint(0, NUM_CLASSES, batch_size).reshape(-1, 1), num_classes=NUM_CLASSES)\n        random_types = to_categorical(y_type[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_TYPES)\n        random_colors = to_categorical(y_color[i*batch_size:(i+1)*batch_size].reshape(-1, 1), num_classes=NUM_COLORS)\n        d_g_loss_batch = d_g.train_on_batch(x=[z, random_types, random_colors], y=real)\n   \n        print(\n            'epoch = %d/%d, batch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, i, len(X_train) // batch_size, d_loss_batch, d_g_loss_batch[0]),\n            100*' ',\n            end='\\r'\n        )\n    \n    d_loss.append(d_loss_batch)\n    d_g_loss.append(d_g_loss_batch[0])\n    print('epoch = %d/%d, d_loss=%.3f, g_loss=%.3f' % (e + 1, epochs, d_loss[-1], d_g_loss[-1]), 100*' ')\n\n    if e % 10 == 0:\n        samples = 3 * 3\n        z = np.random.normal(loc=0, scale=1, size=(samples, latent_dim))\n        # labels = to_categorical(np.arange(0, NUM_CLASSES).reshape(-1, 1), NUM_CLASSES)\n        \n        types = to_categorical(np.arange(0, NUM_TYPES).reshape(-1, 1), NUM_TYPES)\n        all_types = np.concatenate([np.vstack([cType] * 3) for cType in types]) \n        \n        colors = to_categorical(np.arange(0, NUM_COLORS).reshape(-1, 1),  NUM_COLORS)\n        all_colors = np.vstack([colors] * 3)\n        \n        x_fake = generator.predict([z, all_types, all_colors])\n        x_fake = np.clip(x_fake, -1, 1)\n        x_fake = (x_fake + 1) * 127\n        x_fake = np.round(x_fake).astype('uint8')\n\n        for k in range(samples):\n            plt.subplot(3, 3, k + 1, xticks=[], yticks=[])\n            plt.imshow(x_fake[k])\n            # plt.title(class_names[k])\n            plt.title(k)\n\n        plt.tight_layout()\n        plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}